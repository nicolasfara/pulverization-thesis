\chapter{\introductionname}
\label{chap:introduction}
%----------------------------------------------------------------------------------------

With the Internet of Things (IoT), more and more devices are connected to the network producing a very large amount of data.
Cloud computing has been established as a technology for acquiring computational power and storage in support of various applications;
however, it is not always suitable for handling all kinds of systems' requirements: latency, security, and privacy are some of the main
concerns. This comes true especially with IoT systems since they produce lots of data and in some scenarios, they must respect real-time constraints.
For these reasons, fog computing tries to overcome the cloud's limitation by defining a computing model that sits between IoT devices and the cloud.
It allows for the collection, aggregation, and processing of data from IoT devices (or more in general edge devices) using a hierarchy of computing
power.
The combination of fog computing with the cloud can reduce data transfers and communication bottlenecks to the cloud, and can also contribute to
reduced latencies since fog computing resources are closer to the edge.

Nevertheless, realizing systems that operate in the edge-cloud continuum is an open challenge~\cite{DBLP:journals/iot/BittencourtISFM18}:
the heterogeneity of the devices combined with the dynamic nature of the requirements that modern systems must have, leveraging the flexibility of
the edge-cloud continuum is found to be as strategic as it is complex.

Different approaches have been proposed to address the challenges of realizing systems that well interoperate in heterogeneous
infrastructures. Some notable methodologies and frameworks are represented by the osmotic computing paradigm~\cite{DBLP:journals/computer/VillariFDRJR19}, DR-BIP and its
extensions~\cite{DBLP:conf/isola/BallouliBBS18,DBLP:conf/soco/BozgaJMS12,DBLP:journals/sttt/NicolaMS20}.
While the first approach is mainly oriented to distributed microservices, the latter is more focused on the orchestration of distributed
applications by dynamically adapting the system to the changing requirements basing the systems on the \emph{motif} concept.

In the CPS context, engineering systems featuring distributed intelligence in a \emph{self-organization} fashion is one of the main relevant
approaches. In this way, the global behaviour of the system is obtained by the interaction of the individual components giving robustness to the
system. The current trend of large-scale, dynamic and heterogeneous Cyber-Physical Systems requires increasingly complex and diverse
infrastructures. Remote clouds offer a seemingly supply of computing, storage, and services on demand, but this comes with the caveat of high
costs and potential latency issues, as well as data protection concerns that must align with the specific requirements of each application. Edge
computing, on the other hand, brings resources closer to users, resulting in reduced latency and increased reactivity, while simultaneously
addressing data dissemination concerns.

As stated before, such infrastructures are not easy to manage and orchestrate, complicating the engineering phase where the logic of the
system tends to be coupled with infrastructure aspects. Generally, this prevents the reusing of design elements across different scenarios by
exploiting the underlying infrastructure opportunistically.

To tackle this problem in~\cite{DBLP:journals/fi/CasadeiPPVW20} the \emph{pulverization approach} is proposed: this framework brakes the system
behaviour into small computational pieces logically linked to sensors and actuators that are continuously executed and scheduled in the available
infrastructure.
In this way, the system can be seamlessly mapped onto a variety of multi-layered deployment infrastructures.
It is based on a flexible logical model which can be decomposed into a set of sub-components with well-defined relationships that can be deployed and
wired separately. The pulverization facilitates the deployment independence of a system, namely the ability to run the application with no change
on various deployments retaining its original functional semantics.
In this way, the application logic will obtain the functional goals independently of the actual deployment since the choice of the deployment
strategy is affected typically by non-functional requirements such as latency, security, performance and cost.
This approach is formalized to provide an unambiguous specification of what constitutes pulverization by clarifying subtle aspects of the model
and state the deployment-independence property rigorously.

\section{Motivation of the thesis work}

At the time of writing, the pulverization approach is tested and validated in a simulated environment.
The simulation represents a very important step to figure out the validity of the approach by testing it in a controlled environment.
In a large view, the simulation represents a powerful tool to validate the correctness of the systems and to identify the
potential problems that may arise in a real deployment. However, closing the gap between a simulated system and its deployment in a real
infrastructure is not trivial and it is more challenging to do it seamlessly.

A desired development process might be to port the simulated system to the real one with as few changes as possible. In this sense, it is
desired to make use of tools that can appropriately handle specific aspects of the infrastructure on which the system will be deployed without the
user having to worry about them, or even worse having to tie platform-specific aspects in the application logic.

As said before, the pulverization approach has been theorized and verified in simulation and for this reason, it is not corroborated by any tools or
frameworks that enable the deployment of systems in a real infrastructure leveraging this approach.

To solve these issues, this thesis aims to pave the way for closing the gap between the simulation of systems and their deployment by
leveraging the pulverization approach via a dedicated framework.

The developed framework leverages the pulverization approach to orchestrate distributed applications in the edge-cloud continuum.
The framework aims to be versatile enough to allow pulverization in non-aggregate systems, thus expanding its scope of applications beyond aggregate
computing.

The framework is hosted in Kotlin multiplatform, which allows the framework to be used on several platforms, including
Android, iOS, JVM and native target. This variety of platforms is fundamental to enable the framework to be used in a variety of scenarios, spanning
from cloud servers to embedded devices. Another relevant technology adopted in the framework is RabbitMQ, which is a message broker that allows
communication between the different components of the system. The decision to use RabbitMQ is justified by its compatibility with multiple protocols,
including AMQP, MQTT, and WebSocket, which enables a broad spectrum of supported devices and platforms. Furthermore, RabbitMQ facilitates several
communication patterns, such as publish/subscribe, request/reply, and routing, thereby offering significant flexibility in how communications should
occur.

To showcase the effectiveness of the framework, some scenarios in the context of CPS have been identified by using the framework to deploy such
systems, highlighting the potential that pulverization has as a methodology.
In particular, the framework is used in conjunction with \emph{embedded systems} to recreate a heterogeneous infrastructure where the framework
runs on.

For what concerns the testing of the framework and performance evaluation, an exhaustive test suite (composed of unit and integration tests) has been
developed to validate the operational semantics of the framework.
Moreover, as stated above, the framework is tested in real scenarios by deploying a set of demos that showcase the potential of the framework and its
resilience to failures.
In future work, evaluating the performance of various deployment strategies of a given system and their impact on communication in terms of latency 
and throughput represents a relevant topic to be investigated.

%
\paragraph{Thesis Structure.} % Optional paragraph title
%
Accordingly, the remainder of this thesis is structured as follows.
%
\Cref{chap:background} discusses the background and related works.
%
\Cref{chap:requirements} summarize the requirements of the framework and give an overview of relevant deployment scenarios that are worth
to be considered during the validation of the framework.
%
\Cref{chap:design} presents the framework and its architectural design.
%
\Cref{chap:implementation} describes the implementation details of the framework.
%
\Cref{chap:validation} shows the validation process of the framework, including the experimental setup and the results obtained by the demos.
%
Finally, \Cref{chap:conclusions} concludes this thesis by summarizing its main contribution, with a focus on future works.
